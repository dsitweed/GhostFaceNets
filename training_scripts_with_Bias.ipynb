{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 08:44:26.093321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:26.093365: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-15 08:44:29.234998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-15 08:44:29.235380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-04-15 08:44:29.235937: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/ky/anaconda3/envs/ghost_face/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import losses, train, GhostFaceNets, GhostFaceNets_with_Bias\n",
    "import tensorflow as tf\n",
    "import keras_cv_attention_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Remove the below for better accuracies and keep it for faster training\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Change BatchNormalization momentum and epsilon default value.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`input_tensors` must have the same structure as model.input\nReference structure: [<KerasTensor shape=(None, 112, 112, 3), dtype=float16, sparse=False, name=input_layer>]\nReceived structure: <KerasTensor shape=(None, 112, 112, 3), dtype=float32, sparse=None, name=keras_tensor_1584>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/models/cloning.py:261\u001b[0m, in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_same_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/utils/tree.py:305\u001b[0m, in \u001b[0;36massert_same_structure\u001b[0;34m(a, b, check_types)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a_structure \u001b[38;5;241m!=\u001b[39m b_structure:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a` and `b` don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have the same structure. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: structure of a=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma_structure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructure of b=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_structure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_types:\n",
      "\u001b[0;31mValueError\u001b[0m: `a` and `b` don't have the same structure. Received: structure of a=PyTreeSpec(*, NoneIsLeaf), structure of b=PyTreeSpec([*], NoneIsLeaf)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39mbuildin_models(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghostnetv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, emb_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, output_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGDC\u001b[39m\u001b[38;5;124m'\u001b[39m, bn_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, bn_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      4\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39madd_l2_regularizer_2_model(basic_model, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, apply_to_batch_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m \u001b[43mGhostFaceNets_with_Bias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace_ReLU_with_PReLU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasic_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Strides of 1\u001b[39;00m\n\u001b[1;32m      8\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39mbuildin_models(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghostnetv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, emb_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, output_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGDC\u001b[39m\u001b[38;5;124m'\u001b[39m, bn_momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, bn_epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/GhostFaceNets_with_Bias.py:173\u001b[0m, in \u001b[0;36mreplace_ReLU_with_PReLU\u001b[0;34m(model, target_activation, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[1;32m    172\u001b[0m input_tensors \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(model\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_ReLU\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/models/cloning.py:105\u001b[0m, in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Functional):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# If the get_config() method is the same as a regular Functional\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# model, we're safe to use _clone_functional_model (which relies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# or input_tensors are passed, we attempt it anyway\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# in order to preserve backwards compatibility.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mis_default(model\u001b[38;5;241m.\u001b[39mget_config) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    103\u001b[0m         clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors\n\u001b[1;32m    104\u001b[0m     ):\n\u001b[0;32m--> 105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_clone_functional_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclone_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Case of a custom model class\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clone_function \u001b[38;5;129;01mor\u001b[39;00m input_tensors:\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/models/cloning.py:263\u001b[0m, in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    261\u001b[0m         tree\u001b[38;5;241m.\u001b[39massert_same_structure(input_tensors, model\u001b[38;5;241m.\u001b[39minput)\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`input_tensors` must have the same structure as model.input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReference structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39minput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mReceived structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_tensors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: Input(batch_shape\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype, name\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    271\u001b[0m         model\u001b[38;5;241m.\u001b[39minput,\n\u001b[1;32m    272\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `input_tensors` must have the same structure as model.input\nReference structure: [<KerasTensor shape=(None, 112, 112, 3), dtype=float16, sparse=False, name=input_layer>]\nReceived structure: <KerasTensor shape=(None, 112, 112, 3), dtype=float32, sparse=None, name=keras_tensor_1584>"
     ]
    }
   ],
   "source": [
    "#GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GhostFaceNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosFaceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.CosFaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.CosFaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcenter ArcFace Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms1m-retinaface-t1 (MS1MV3) dataset\n",
    "data_basic_path = 'datasets/ms1m-retinaface-t1'\n",
    "data_path = data_basic_path + '_112x112_folders'\n",
    "eval_paths = [os.path.join(data_basic_path, ii) for ii in ['lfw.bin', 'cfp_fp.bin', 'agedb_30.bin']]\n",
    "\n",
    "# (MS1MV2) dataset\n",
    "data_path = 'datasets/faces_emore_112x112_folders'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# GhostFaceNetV2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Strides of 2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m \u001b[43mGhostFaceNets_with_Bias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuildin_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mghostnetv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGDC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39madd_l2_regularizer_2_model(basic_model, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, apply_to_batch_normal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m GhostFaceNets_with_Bias\u001b[38;5;241m.\u001b[39mreplace_ReLU_with_PReLU(basic_model)\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/GhostFaceNets_with_Bias.py:52\u001b[0m, in \u001b[0;36mbuildin_models\u001b[0;34m(stem_model, dropout, emb_shape, input_shape, output_layer, bn_momentum, bn_epsilon, add_pointwise_conv, pointwise_conv_act, use_bias, scale, weights, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuildin_models\u001b[39m(\n\u001b[1;32m     37\u001b[0m     stem_model,\n\u001b[1;32m     38\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     50\u001b[0m ):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stem_model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 52\u001b[0m         xx \u001b[38;5;241m=\u001b[39m \u001b[43m__init_model_from_name__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m         name \u001b[38;5;241m=\u001b[39m stem_model\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/GhostFaceNets_with_Bias.py:17\u001b[0m, in \u001b[0;36m__init_model_from_name__\u001b[0;34m(name, input_shape, weights, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name_lower \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghostnetv2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbackbones\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ghostv2\n\u001b[0;32m---> 17\u001b[0m     xx \u001b[38;5;241m=\u001b[39m \u001b[43mghostv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGhostNetV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mstem_strides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mwidth_mul\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_ghost_module_v1_stacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# num of `ghost_module` stcks on the head, others are `ghost_module_multiply`, set `-1` for all using `ghost_module`\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m                            \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m112\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m112\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mghostnetv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/backbones/ghostv2.py:117\u001b[0m, in \u001b[0;36mGhostNetV2\u001b[0;34m(stem_width, stem_strides, width_mul, num_ghost_module_v1_stacks, input_shape, num_classes, activation, classifier_activation, dropout, pretrained, model_name, kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m out_channel \u001b[38;5;241m==\u001b[39m nn\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m stride \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     use_ghost_module_multiply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m num_ghost_module_v1_stacks \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m stack_id \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_ghost_module_v1_stacks \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     nn \u001b[38;5;241m=\u001b[39m \u001b[43mghost_bottleneck\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_ghost_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mse_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ghost_module_multiply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstack_name\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m nn \u001b[38;5;241m=\u001b[39m conv2d_no_bias(nn, make_divisible(first_ghost_channels[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m width_mul, \u001b[38;5;241m4\u001b[39m), \u001b[38;5;241m1\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m nn \u001b[38;5;241m=\u001b[39m batchnorm_with_activation(nn, activation\u001b[38;5;241m=\u001b[39mactivation, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/backbones/ghostv2.py:69\u001b[0m, in \u001b[0;36mghost_bottleneck\u001b[0;34m(inputs, out_channel, first_ghost_channel, kernel_size, strides, se_ratio, shortcut, use_ghost_module_multiply, activation, name)\u001b[0m\n\u001b[1;32m     66\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ghost_module_multiply:\n\u001b[0;32m---> 69\u001b[0m     nn \u001b[38;5;241m=\u001b[39m \u001b[43mghost_module_multiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_ghost_channel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mghost_1_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     nn \u001b[38;5;241m=\u001b[39m ghost_module(inputs, first_ghost_channel, activation\u001b[38;5;241m=\u001b[39mactivation, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mghost_1_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/backbones/ghostv2.py:48\u001b[0m, in \u001b[0;36mghost_module_multiply\u001b[0;34m(inputs, out_channel, activation, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m activation_by_name(shortcut, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(f\"{shortcut.shape = }, {nn.shape = }\")\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(shortcut, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# shortcut = keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(shortcut)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# if int(shortcut.shape[1] - nn.shape[1]) > 0 or int(shortcut.shape[2] - nn.shape[2]) > 0:\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#     shortcut = shortcut[:, :nn.shape[1], :nn.shape[2]]\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# shortcut = keras.layers.Resizing(nn.shape[1], nn.shape[2])(shortcut)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMultiply()([shortcut, nn])\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GhostFaceNetV1\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> L2 regularizer value from basic_model: 0.00025\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=checkpoints/ghostnetv2_w1.3_s2_topk.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#GhostFaceNetV2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Strides of 2\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m tt \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mghostnetv2_w1.3_s2_topk.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbasic_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbasic_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_decay_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_weight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Strides of 1\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tt \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mTrain(data_path, eval_paths\u001b[38;5;241m=\u001b[39meval_paths,\n\u001b[1;32m     10\u001b[0m     save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mghostnetv2_w1.3_s1_topk.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     basic_model\u001b[38;5;241m=\u001b[39mbasic_model, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lr_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, lr_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, lr_decay_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m45\u001b[39m, lr_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,\n\u001b[1;32m     12\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, random_status\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eval_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/train.py:139\u001b[0m, in \u001b[0;36mTrain.__init__\u001b[0;34m(self, data_path, save_path, eval_paths, basic_model, model, compile, output_weight_decay, custom_objects, pretrained, batch_size, lr_base, lr_decay, lr_decay_steps, lr_min, lr_warmup_steps, eval_freq, random_status, random_cutout_mask_area, image_per_class, samples_per_mining, mixup_alpha, partial_fc_split, teacher_model_interf, sam_rho, vpl_start_iters, vpl_allowed_delta)\u001b[0m\n\u001b[1;32m    136\u001b[0m     my_evals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msave_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(save_path)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_history, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_checkpoint, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgently_stop \u001b[38;5;241m=\u001b[39m \u001b[43mmyCallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_callbacks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmy_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_decay_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_decay_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_warmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_warmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgently_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# may not working for windows\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_evals, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_callbacks \u001b[38;5;241m=\u001b[39m my_evals, []\n",
      "File \u001b[0;32m~/NguyenVanKy/2023_2/GhostFaceNets/myCallbacks.py:261\u001b[0m, in \u001b[0;36mbasic_callbacks\u001b[0;34m(checkpoint, evals, lr, lr_decay, lr_min, lr_decay_steps, lr_warmup_steps)\u001b[0m\n\u001b[1;32m    259\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(checkpoint_base)\n\u001b[1;32m    260\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint_base, checkpoint)\n\u001b[0;32m--> 261\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_weights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# model_checkpoint = ModelCheckpoint(checkpoint, verbose=1)\u001b[39;00m\n\u001b[1;32m    263\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(checkpoint)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ghost_face/lib/python3.9/site-packages/keras/src/callbacks/model_checkpoint.py:183\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_weights_only:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `save_weights_only=True` in `ModelCheckpoint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, the filepath provided must end in `.weights.h5` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras weights format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: When using `save_weights_only=True` in `ModelCheckpoint`, the filepath provided must end in `.weights.h5` (Keras weights format). Received: filepath=checkpoints/ghostnetv2_w1.3_s2_topk.h5"
     ]
    }
   ],
   "source": [
    "#GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1_topk.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First, Train with `lossTopK = 3` \"\"\"\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer, \"lossTopK\": 3},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50, \"lossTopK\": 3},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Then drop non-dominant subcenters and high-confident noisy data, which is `>75 degrees` \"\"\"\n",
    "import data_drop_top_k\n",
    "# data_drop_top_k.data_drop_top_k('./checkpoints/TT_mobilenet_topk_bs256.h5', '/datasets/faces_casia_112x112_folders/', limit=20)\n",
    "new_data_path = data_drop_top_k.data_drop_top_k(tt.model, tt.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train with the new dataset again, this time `lossTopK = 1` \"\"\"\n",
    "tt.reset_dataset(new_data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can continue training the model or start training again and considering the generated dataset as a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models from scatch using the new generated dataset\n",
    "\n",
    "# New Cleaned Dataset\n",
    "data_path = 'Path_To_New_Generated_Dataset'\n",
    "eval_paths = ['datasets/faces_emore/lfw.bin', 'datasets/faces_emore/cfp_fp.bin', 'datasets/faces_emore/agedb_30.bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv1\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, scale=True, use_bias=True, strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "# Strides of 2\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)\n",
    "\n",
    "# Strides of 1\n",
    "basic_model = GhostFaceNets_with_Bias.buildin_models(\"ghostnetv2\", dropout=0, emb_shape=512, output_layer='GDC', bn_momentum=0.9, bn_epsilon=1e-5, stem_strides=1)\n",
    "basic_model = GhostFaceNets_with_Bias.add_l2_regularizer_2_model(basic_model, weight_decay=5e-4, apply_to_batch_normal=False)\n",
    "basic_model = GhostFaceNets_with_Bias.replace_ReLU_with_PReLU(basic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV1\n",
    "# Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "# Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv1_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GhostFaceNetV2\n",
    "#Strides of 2\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s2.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)\n",
    "\n",
    "#Strides of 1\n",
    "tt = train.Train(data_path, eval_paths=eval_paths,\n",
    "    save_path='ghostnetv2_w1.3_s1.h5',\n",
    "    basic_model=basic_model, model=None, lr_base=0.1, lr_decay=0.5, lr_decay_steps=45, lr_min=1e-5,\n",
    "    batch_size=128, random_status=0, eval_freq=1, output_weight_decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "sch = [\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=32), \"epoch\": 1, \"optimizer\": optimizer},\n",
    "    {\"loss\": losses.ArcfaceLoss(scale=64), \"epoch\": 50},\n",
    "]\n",
    "tt.train(sch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
